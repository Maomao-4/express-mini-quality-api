# **express-mini-quality-api** 

### **Parcial III ‚Äì Calidad de Software Avanzado**

---

# üß© 1. Diferencia entre CI y CD

### ‚úî **Integraci√≥n Continua (CI)**

La integraci√≥n continua es un proceso en el que cada cambio enviado al repositorio ejecuta autom√°ticamente:

* An√°lisis est√°tico (ESLint)
* Pruebas unitarias (Jest + Supertest)
* Verificaci√≥n de cobertura m√≠nima
* Validaci√≥n del proyecto en m√∫ltiples versiones de Node

El objetivo de CI es detectar errores **r√°pidamente**, mantener el c√≥digo estable y asegurar que cada commit respete las reglas de calidad definidas.

### ‚úî **Entrega Continua (CD)**

La entrega continua garantiza que, despu√©s de pasar CI:

* El proyecto queda **listo para ser entregado o desplegado**.
* Los artefactos (como el reporte de cobertura) se generan autom√°ticamente.
* No es necesaria intervenci√≥n manual para validar calidad.

En este proyecto, CD se evidencia en la **subida autom√°tica del artifact de cobertura** y en mantener siempre el repositorio en un estado ‚Äúdeploy-ready‚Äù.

---

# üß± 2. Estrategia de calidad aplicada al proyecto

### ‚úî Herramientas usadas

* **Node.js + Express** ‚Üí servidor API
* **Jest + Supertest** ‚Üí pruebas unitarias y HTTP
* **ESLint** ‚Üí an√°lisis est√°tico
* **GitHub Actions** ‚Üí pipeline CI/CD
* **act** ‚Üí ejecuci√≥n local del workflow
* **Cobertura m√≠nima** ‚Üí 80% configurado en `jest.config.js`

### ‚úî Validaciones del proyecto

* Todos los endpoints probados
* Cobertura m√≠nima respetada
* Linter sin errores
* Pipeline configurado para fallar si:

  * Linter falla
  * Tests fallan
  * Cobertura insuficiente

---

# üß™ 3. Ejecuci√≥n local del pipeline con `act`

## üìå 3.1. `act -l`

**Comando usado:**

```
act -l
```

üì∏ **Inserta aqu√≠ tu imagen del comando `act -l`:**

> *(CAPTURA #1)*

---

## üìå 3.2. `act push` con linter + tests + coverage

**Comando usado:**

```
act push
```

Esto ejecuta exactamente los mismos pasos que GitHub Actions:

* Instalaci√≥n de dependencias
* ESLint
* Pruebas unitarias
* Cobertura
* Verificaci√≥n del umbral
* Subida de artifacts

üì∏ **Inserta aqu√≠ la captura completa del pipeline ejecutado con `act`:**

> *(CAPTURA #2 ‚Äì donde se vea ESLint, los tests y la cobertura)*

---

# üîç 4. Evidencia de Linter (ESLint)

### ‚úî ¬øQu√© valida el linter?

* Estilo del c√≥digo
* Comillas simples
* Puntos y coma
* Variables mal usadas
* Errores comunes de sintaxis

### ‚úî ¬øPor qu√© es importante?

Garantiza un estilo **consistente** y evita errores que no son detectados por tests.

---

## üìå 4.1. Ejecuci√≥n de lint (sin errores)

**Comando:**

```
npm run lint
```

üì∏ **Inserta aqu√≠ captura del lint pasando correctamente:**

> *(CAPTURA #3)*

---

## üìå 4.2. Fix (si fue necesario)

**Comando:**

```
npx eslint . --fix
```

üì∏ **Inserta aqu√≠ la captura del fix corrigiendo errores:**

> *(CAPTURA #4)*

---

# üß™ 5. Evidencias de pruebas locales

## üìå 5.1. Pruebas unitarias

**Comando usado:**

```
npm test
```

üì∏ **Inserta captura de las pruebas pasando:**

> *(CAPTURA #5)*

---

## üìå 5.2. Pruebas con cobertura

**Comando usado:**

```
npm test -- --coverage
```

üì∏ **Inserta captura de la tabla de cobertura:**

> *(CAPTURA #6)*

Debes mostrar:

* Cobertura ‚â• 80%
* Tests totales
* Tests pasados
* Archivo con estad√≠sticas

---

# ‚ö†Ô∏è 6. Ejemplo de ejecuci√≥n fallida del pipeline (requerido en el parcial)

Para esta evidencia:

* Romp√≠ un test / romp√≠ ESLint / baj√© cobertura
* Hice push
* El pipeline fall√≥ como se esperaba

üì∏ **Inserta aqu√≠ la captura del run fallido (GitHub Actions en rojo):**

> *(CAPTURA #7)*

### ‚úî Explicaci√≥n breve:

> *Describe aqu√≠ qu√© rompiste (por ejemplo modificar un valor esperado en un test) y por qu√© Actions lo detect√≥.*

---

# ‚úÖ 7. Ejecuci√≥n exitosa del pipeline

Despu√©s de corregir el error:

üì∏ **Inserta aqu√≠ captura del pipeline en verde (run exitoso):**

> *(CAPTURA #8)*

### ‚úî Explicaci√≥n breve:

> *Explica qu√© corregiste y c√≥mo regres√≥ a verde.*

---

# ü§ñ 8. Reflexi√≥n sobre IA y √©tica

### ‚úî M√©todos posibles para detectar c√≥digo generado por IA

1. An√°lisis de estilo (repetici√≥n, estructuras uniformes)
2. Herramientas autom√°ticas de detecci√≥n (no siempre confiables)
3. Comparaci√≥n con otros trabajos del estudiante

### ‚úî Por qu√© **NO** puede garantizarse detecci√≥n al 100%

* La IA puede imitar estilos humanos
* Los estudiantes pueden reescribir c√≥digo
* No existen marcadores t√©cnicos que aseguren autor√≠a
* El c√≥digo puede ser generado por humanos pero ‚Äúparecer IA‚Äù o viceversa

### ‚úî Propuesta de pol√≠tica √©tica

* La IA es aceptable para **investigar, aclarar conceptos o pedir explicaciones**
* **C√≥digo del parcial debe ser 100% escrito por el estudiante**
* Prohibido generar archivos completos o soluciones autom√°ticas
* El estudiante debe poder explicar cada l√≠nea del proyecto
